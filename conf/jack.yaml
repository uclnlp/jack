config: './conf/jack.yaml'

description: >
  Train and Evaluate a Machine Reader

# Reader model to use, see jack/readers/implementations.py for options
model: null

# name of this reader, serves as kind of a namespace for created parameters, defaults to name of the model
name: null

# seed will not be inherited (because of sacred) so you need to set it for all child configs
seed: 1337

# Run in debug mode, in which case the training file is also used for testing
debug: False

# If in debug mode, how many examples should be used (default 10)
debug_examples: 10

# training file
train: null

# dev file
dev: null

# test file
test: null

# Batch size for training data, default 128
batch_size: 128

# Batch size for development data, default 128
dev_batch_size: 128

# Size of the input representation (embeddings), is automatically overwritten when pre-trained embeddings are provided
repr_dim_input: 128

# Size of the hidden representations, default 128
repr_dim: 128

# Use fixed vocab of pretrained embeddings
vocab_from_embeddings: False

# Continue training pretrained embeddings together with model parameters
train_pretrain: False

# Normalize pretrained embeddings, default True (randomly initialized embeddings have expected unit norm too)
normalize_pretrain: False

# [word2vec] or [glove] format of embeddings to be loaded
embedding_format: null

# format of embeddings to be loaded
embedding_file: null

vocab_maxsize: 1000000000000

vocab_minfreq: 2

# Should there be separate vocabularies for questions, supports, candidates and answers. This needs to be set to True for candidate-based methods
vocab_sep: True

# Optimizer, default Adam
optimizer: 'adam'

# Learning rate, default 0.001
learning_rate: 0.001

# Learning rate decay, default 0.5
learning_rate_decay: 0.5

# L2 regularization weight, default 0.0
l2: 0.0

# Gradients clipped between [-clip_value, clip_value] (default 0.0; no clipping)
clip_value: 0.0

# Probability for dropout on output (set to 0.0 for no dropout)
dropout: 0.0

# Number of epochs to train for, default 5
epochs: 5

# Number of batches before validation on devset. If null then after each epoch.
validation_interval: null

# Folder for tensorboard logs
tensorboard_folder: null

# Filename to log the metrics of the EvalHooks
write_metrics_to: null

# If the vocabulary should be pruned to the most frequent words
prune: False

# Directory to write reader to
model_dir: null

# interval for logging eta, training loss, etc
log_interval: 100

# lowercase texts
lowercase: True

# path to output directory
output_dir: './out/'

# path to SQLite DB for storing experiments
experiments_db: './out/experiments.db'

# loader for the dataset, ['jack', 'squad', 'snli'] are supported. For everything else convert to jtr format first.
loader: 'jack'
